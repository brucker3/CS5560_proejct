{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KDM-project-notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOkBHFi23u5nEHJ6AVPKDw0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brucker3/CS5560_proejct/blob/main/code/KDM_project_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66hHm7wqcvRp"
      },
      "source": [
        "import Importing neede libraries for preprocessing and model budiling \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr6_8aLScjUl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11777c03-90a9-4110-dec8-831e3520c60d"
      },
      "source": [
        "import nltk\n",
        "import io\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.cluster.util import cosine_distance\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt') # one time execution\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGXlu-HCc3kU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ae2edccb-b188-4294-f63b-a06f88208c52"
      },
      "source": [
        "\n",
        "df = pd.read_csv(\"/content/news_summary_more.csv\")\n",
        "df.head()\n",
        "df.tail()\n",
        "#print(df['text'][1])\n",
        "\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "\n",
        "#df = pd.read_csv(\"../content/news_summmary.csv\")\n",
        "#df = pd.read_csv(io.BytesIO(uploaded[\"/content/news_summary.csv\"]))\n",
        "#text = \"/content/news_summary.csv\"\n",
        "\n",
        "#io.BytesIO(uploaded[\"/content/news_summary.csv\"]))\n",
        "\n",
        "# opening and converting read in files to use able form \n",
        "#txt1 = open(text, \"r\")\n",
        "#print(txt1)\n",
        "#text1_sring = txt1.read()\n",
        "#print(\"_-------------\")\n",
        "#print(text1_string)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headlines</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>98396</th>\n",
              "      <td>CRPF jawan axed to death by Maoists in Chhatti...</td>\n",
              "      <td>A CRPF jawan was on Tuesday axed to death with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98397</th>\n",
              "      <td>First song from Sonakshi Sinha's 'Noor' titled...</td>\n",
              "      <td>'Uff Yeh', the first song from the Sonakshi Si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98398</th>\n",
              "      <td>'The Matrix' film to get a reboot: Reports</td>\n",
              "      <td>According to reports, a new version of the 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98399</th>\n",
              "      <td>Snoop Dogg aims gun at clown dressed as Trump ...</td>\n",
              "      <td>A new music video shows rapper Snoop Dogg aimi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98400</th>\n",
              "      <td>Madhesi Morcha withdraws support to Nepalese g...</td>\n",
              "      <td>Madhesi Morcha, an alliance of seven political...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               headlines                                               text\n",
              "98396  CRPF jawan axed to death by Maoists in Chhatti...  A CRPF jawan was on Tuesday axed to death with...\n",
              "98397  First song from Sonakshi Sinha's 'Noor' titled...  'Uff Yeh', the first song from the Sonakshi Si...\n",
              "98398         'The Matrix' film to get a reboot: Reports  According to reports, a new version of the 199...\n",
              "98399  Snoop Dogg aims gun at clown dressed as Trump ...  A new music video shows rapper Snoop Dogg aimi...\n",
              "98400  Madhesi Morcha withdraws support to Nepalese g...  Madhesi Morcha, an alliance of seven political..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_u01tb6jQ1H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03826cd2-2dca-471d-966b-e7b36e3d7a89"
      },
      "source": [
        "# sentence tokinization \n",
        "sentences = []\n",
        "df.text = df['text']\n",
        "df2 =  df.text[:10000]\n",
        "print(len(df2))\n",
        "\n",
        "for s in df2:\n",
        "  sentences.append(s)\n",
        "  \n",
        "\n",
        "#checking tokinization output \n",
        "print(sentences[:9])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "[\"Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\", \"Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\", \"New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\", 'With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to â\\x82¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.', 'Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I\\'ve known Hirani for many years...What if it\\'s not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman. But in this case, we need to reserve our judgment,\" she added. Hirani has been accused by an assistant who worked in \\'Sanju\\'.', 'Pakistani singer Rahat Fateh Ali Khan has denied receiving any notice from the Enforcement Directorate over allegedly smuggling foreign currency out of India. \"It would have been better if the authorities would have served the notice first if any and then publicised this,\" reads a press release issued on behalf of Rahat. The statement further called the allegation \"bizarre\".', \"India recorded their lowest ODI total in New Zealand after getting all out for 92 runs in 30.5 overs in the fourth ODI at Hamilton on Thursday. Seven of India's batsmen were dismissed for single-digit scores, while their number ten batsman Yuzvendra Chahal top-scored with 18*(37). India's previous lowest ODI total in New Zealand was 108.\", 'Weeks after ex-CBI Director Alok Verma told the Department of Personnel and Training to consider him retired, the Home Ministry asked him to join work on the last day of his fixed tenure as Director on Thursday. The ministry directed him to immediately join as DG, Fire Services, the post he was transferred to after his removal as CBI chief.', 'Andhra Pradesh CM N Chandrababu Naidu has said, \"When I met then US President Bill Clinton, I addressed him as Mr Clinton, not as \\'sir\\'. (PM Narendra) Modi is my junior in politics...I addressed him as sir 10 times.\" \"I did this...to satisfy his ego in the hope that he will do justice to the state,\" he added.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjKZ60PoxGbT"
      },
      "source": [
        "# remove punctuations, numbers and special characters\n",
        "clean_sentences = pd.Series(sentences).str.replace(\"[^a-zA-Z]\", \" \")\n",
        "clean_sentences = [s.lower() for s in clean_sentences]\n",
        "\n",
        "#remove stopwords from the sentences\n",
        "def remove_stopwords(sen):\n",
        "    sen_new = \" \".join([i for i in sen if i not in stop_words])\n",
        "    return sen_new\n",
        "\n",
        "\n",
        "\n",
        "# remove stopwords from the sentences\n",
        "clean_sentences = [remove_stopwords(r.split()) for r in clean_sentences]\n",
        "\n",
        "#print(sentences[0])\n",
        "#print(\"-----------\")\n",
        "#print(clean_sentences)\n",
        "#print(type(clean_sentences))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#for sentence in sentences:\n",
        " #   print(sentence)\n",
        " #   sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    \n",
        "#print(sentences[0])\n",
        "\n",
        "\n",
        "# make alphabets lowercase\n",
        "#clean_sentences = [s.lower() for s in clean_sentences]\n",
        "\n",
        "#simple fuction to remove stop words \n",
        "#def word_remover(sentenc):\n",
        "#    sentenc_new = \" \".join([i for i in sentenc if i not in stop_words])\n",
        "#    return sentenc_new\n",
        "\n",
        "\n",
        "#clean_sentences = [word_remover(r.split()) for r in clean_sentences]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIRe5frGxN_1",
        "outputId": "e3d59262-f5ed-4279-afd2-9bd56e8354ad"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n",
        "\n",
        "# Extract word vectors\n",
        "word_embeddings = {}\n",
        "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = coefs\n",
        "f.close()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-16 18:42:25--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-04-16 18:42:25--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-04-16 18:42:26--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.2’\n",
            "\n",
            "glove.6B.zip.2      100%[===================>] 822.24M  5.29MB/s    in 2m 41s  \n",
            "\n",
            "2021-04-16 18:45:06 (5.12 MB/s) - ‘glove.6B.zip.2’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtSB8YCe3q5X"
      },
      "source": [
        "# Extract word vectors\n",
        "word_embeddings = {}\n",
        "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    word_embeddings[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZpXzTEy5EaG"
      },
      "source": [
        "sentence_vectors = []\n",
        "for i in clean_sentences:\n",
        "  if len(i) != 0:\n",
        "    v = sum([word_embeddings.get(w, np.zeros((100,))) for w in i.split()])/(len(i.split())+0.001)\n",
        "  else:\n",
        "    v = np.zeros((100,))\n",
        "  sentence_vectors.append(v)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDxQ6pNp5U8e"
      },
      "source": [
        "# similarity matrix\n",
        "sim_mat = np.zeros([len(sentences), len(sentences)])\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  for j in range(len(sentences)):\n",
        "    if i != j:\n",
        "      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,100), sentence_vectors[j].reshape(1,100))[0,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4s14H-V5jdm"
      },
      "source": [
        "nx_graph = nx.from_numpy_array(sim_mat)\n",
        "scores = nx.pagerank(nx_graph)\n",
        "ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)\n",
        "\n",
        "\n",
        "# Extract top 10 sentences as the summary\n",
        "for i in range(10):\n",
        "  print(ranked_sentences[i][1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}